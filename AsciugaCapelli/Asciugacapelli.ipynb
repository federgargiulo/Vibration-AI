{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Importo le librerie \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import to_categorical, normalize, plot_model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import SGD\n",
        "import scikeras\n",
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "id": "ewOhfehyOiN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras[tensorflow]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U2BI_OI_OsV",
        "outputId": "bd6ba771-d74e-43e1-93f7-5575f5d70a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikeras[tensorflow] in /usr/local/lib/python3.8/dist-packages (0.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikeras[tensorflow]) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras[tensorflow]) (23.0)\n",
            "Requirement already satisfied: tensorflow>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from scikeras[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.22.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.7.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (1.51.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (0.30.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (23.1.21)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (4.5.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (3.19.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (15.0.6.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (2.16.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (2.25.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (3.14.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.11.0->scikeras[tensorflow]) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importo il dataset e definisco il numero di input e di classi di output\n",
        "\n",
        "AC = pd.read_excel('/content/AscVel.xlsx')\n",
        "print(AC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG4pewDoOsmP",
        "outputId": "49212297-a29f-4e7b-beb7-7ed8dfdb0ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Ax      fx          Ay      fy          Az      fz  Labels\n",
            "0      0.911394  7109.0    0.920176    19.0    3.827030   390.0       0\n",
            "1      0.837911  4082.0    0.916373  9042.0    3.379478  5664.0       0\n",
            "2      0.825080  9082.0    0.896009  8691.0    2.916811  7714.0       0\n",
            "3      0.823855  1660.0    0.840291   527.0    2.815620  9062.0       0\n",
            "4      0.820812  4628.0    0.837213  6992.0    2.807744  9277.0       0\n",
            "..          ...     ...         ...     ...         ...     ...     ...\n",
            "145  112.656021   722.0  107.430817  2675.0  292.399017  2675.0       2\n",
            "146   92.967850   234.0   87.457001   722.0  273.965240   722.0       2\n",
            "147   49.133049   742.0   73.032364  2910.0  178.480057  2910.0       2\n",
            "148   35.290642   214.0   63.397198   957.0  165.834213   742.0       2\n",
            "149   24.261366   761.0   53.787792  2636.0  160.796646  2636.0       2\n",
            "\n",
            "[150 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitto il dataset (Opzionale)\n",
        "#X_train,X_test,Y_train,Y_test = train_test_split(X_train,Y_train,test_size=0.2)\n"
      ],
      "metadata": {
        "id": "LVczlToHPSBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68adfca4-62ba-4a00-b559-c30e4d59681b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Ax      fx          Ay      fy          Az      fz\n",
            "0      0.911394  7109.0    0.920176    19.0    3.827030   390.0\n",
            "1      0.837911  4082.0    0.916373  9042.0    3.379478  5664.0\n",
            "2      0.825080  9082.0    0.896009  8691.0    2.916811  7714.0\n",
            "3      0.823855  1660.0    0.840291   527.0    2.815620  9062.0\n",
            "4      0.820812  4628.0    0.837213  6992.0    2.807744  9277.0\n",
            "..          ...     ...         ...     ...         ...     ...\n",
            "145  112.656021   722.0  107.430817  2675.0  292.399017  2675.0\n",
            "146   92.967850   234.0   87.457001   722.0  273.965240   722.0\n",
            "147   49.133049   742.0   73.032364  2910.0  178.480057  2910.0\n",
            "148   35.290642   214.0   63.397198   957.0  165.834213   742.0\n",
            "149   24.261366   761.0   53.787792  2636.0  160.796646  2636.0\n",
            "\n",
            "[150 rows x 6 columns]\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparo il dataset per addestrare la rete\n",
        "\n",
        "X_train = AC.loc[:,'Ax':'fz']\n",
        "Y_train = AC.loc[:,'Labels']\n",
        "Y_train = to_categorical(Y_train)"
      ],
      "metadata": {
        "id": "FLhHpZLpzday"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Addestro il modello\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(25,input_dim = 6,activation = 'relu'))\n",
        "model.add(Dense(25,activation = 'relu'))\n",
        "model.add(Dense(3,activation = 'softmax'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,epochs = 100,batch_size = 5,verbose = 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y2AcdLjPXE9",
        "outputId": "a3226491-c6c9-46b3-bc7c-2b32b13eed61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 1s 2ms/step - loss: 127.2239 - accuracy: 0.3267\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 35.5914 - accuracy: 0.4067\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 22.5821 - accuracy: 0.4533\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 14.5312 - accuracy: 0.4867\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 10.7608 - accuracy: 0.5067\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 8.0783 - accuracy: 0.5133\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 6.3009 - accuracy: 0.6133\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 5.8831 - accuracy: 0.6333\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 5.4053 - accuracy: 0.6533\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 4.5298 - accuracy: 0.6733\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 3.8191 - accuracy: 0.6600\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 4.3847 - accuracy: 0.6867\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 3.3233 - accuracy: 0.7333\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 3.5149 - accuracy: 0.7000\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 3.4047 - accuracy: 0.7133\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 3.0921 - accuracy: 0.7267\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 3.4024 - accuracy: 0.7133\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.4405 - accuracy: 0.7867\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 2.8491 - accuracy: 0.7533\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.8630 - accuracy: 0.7400\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.5485 - accuracy: 0.7733\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.5138 - accuracy: 0.7333\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.1894 - accuracy: 0.8067\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.5498 - accuracy: 0.7800\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.1865 - accuracy: 0.8267\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.5125 - accuracy: 0.7867\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.0067 - accuracy: 0.8000\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.2415 - accuracy: 0.7467\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.6687 - accuracy: 0.8000\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.7610 - accuracy: 0.8200\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.3034 - accuracy: 0.7400\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.0240 - accuracy: 0.8000\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.2126 - accuracy: 0.8000\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.8749 - accuracy: 0.7600\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.5098 - accuracy: 0.8133\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.8022 - accuracy: 0.8133\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.2050 - accuracy: 0.7667\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.3511 - accuracy: 0.8000\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.7875 - accuracy: 0.8400\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.1537 - accuracy: 0.7533\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.8429 - accuracy: 0.8400\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.6937 - accuracy: 0.8133\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.9150 - accuracy: 0.8133\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.6666 - accuracy: 0.7933\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 2.0018 - accuracy: 0.8267\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.1926 - accuracy: 0.7933\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.9086 - accuracy: 0.7733\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.6240 - accuracy: 0.8133\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.0973 - accuracy: 0.7667\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.3935 - accuracy: 0.8333\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.8236 - accuracy: 0.7667\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4726 - accuracy: 0.8400\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.7760 - accuracy: 0.8000\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.5389 - accuracy: 0.8200\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.5749 - accuracy: 0.8133\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.6704 - accuracy: 0.8200\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.5424 - accuracy: 0.8333\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4015 - accuracy: 0.8267\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.5724 - accuracy: 0.8267\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.5873 - accuracy: 0.8333\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4189 - accuracy: 0.8133\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.1659 - accuracy: 0.8467\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.9993 - accuracy: 0.8333\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4187 - accuracy: 0.7867\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.5130 - accuracy: 0.8333\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.1967 - accuracy: 0.8333\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.5373 - accuracy: 0.8400\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.2121 - accuracy: 0.8000\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.3629 - accuracy: 0.8200\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.2622 - accuracy: 0.8533\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.3472 - accuracy: 0.8333\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.5772 - accuracy: 0.8067\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.6312 - accuracy: 0.8133\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.3010 - accuracy: 0.8200\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.1041 - accuracy: 0.8333\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4131 - accuracy: 0.8267\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.3030 - accuracy: 0.8533\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4325 - accuracy: 0.8467\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4003 - accuracy: 0.8467\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.1592 - accuracy: 0.8267\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.1984 - accuracy: 0.8533\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.1530 - accuracy: 0.8533\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4144 - accuracy: 0.8533\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.2085 - accuracy: 0.8600\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4013 - accuracy: 0.8400\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.9286 - accuracy: 0.9000\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.8670 - accuracy: 0.8667\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4763 - accuracy: 0.8667\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.0828 - accuracy: 0.8600\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.1495 - accuracy: 0.8467\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.0287 - accuracy: 0.8667\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.3149 - accuracy: 0.8867\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.0302 - accuracy: 0.8533\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.2866 - accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.9064 - accuracy: 0.8933\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.1516 - accuracy: 0.8600\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.1068 - accuracy: 0.8533\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.0395 - accuracy: 0.8533\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.1420 - accuracy: 0.8933\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.9833 - accuracy: 0.8733\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26644a3880>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction = model.predict(X_test)\n",
        "#print(prediction[:].round())\n",
        "#print(Y_test)\n",
        "\n",
        "#Valuto l'accuracy del modello e ne stampo il plot\n",
        "model.evaluate(X_train,Y_train)\n",
        "model.summary()\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "wwlD1w26_aFc",
        "outputId": "56132d5d-7411-45b5-86d0-d09fe9f807eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0461 - accuracy: 0.8733\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 25)                175       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 25)                650       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 78        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 903\n",
            "Trainable params: 903\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASkAAAGVCAIAAAAt85DbAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO2da1wUR773q4e5DzNc5Co3YVCJoFGiLhJczXFjVl1ABAWjyaLHHDQxBEXDoglRxFsgwgFxc1TC50SzcpMPKhGTGBf3eALGHDEQWBVRUCTIRa7OCAP086Kf9JnDZZjpudQM/r+v6Orq6n919Y+u7qqpH0GSJAIAwOCwcAcAAC8ooD0AwANoDwDwANoDADywlTfKysqOHDmCKxQAmNgsWLBg+/bt9Ob/ee49evSooKDA4CFNQAoKChobG3FHoRfKy8vLy8txR2F6lJeXl5WVKaewR2bKz883VDwTFoIgtm3btmbNGtyB6J7Vq1cjuEk0h7puysD7HgDgAbQHAHgA7QEAHkB7AIAH0B4A4EFb7W3atEksFhMEcevWLZ0ExJiLFy9aWFhcuHABbxiMMfX4h7F582biN9avX6+86/Lly/Hx8WfPnvXw8KAyvPXWW8oZli5dKhaLzczMvL29b968adjAkUKhOHDggKenJ5fLtbS09PHxqa+vP3/+/OHDhwcHB+lsRUVFdAVtbGwYnEhb7Z08efLEiRNaFqITTP0HGaYe/0isra1LSkru3LmTlZVFJ37yySfp6em7du0KDQ29f/++VCqdNGnS6dOnv/76azrPt99+m5+fHxgYWF1d7evra+Cww8PDv/zyy6+++komk/3zn/+USqW9vb1BQUF8Pn/JkiWdnZ1UtuDg4MbGxn/84x/Lly9ndqKJ0+dcsWJFV1dXYGCgnsqXy+X+/v56KhyZfvwjEQgEf/zjH6dNm8bj8aiUQ4cO5eTk5OXlicViOlt6ejqLxYqKiurq6jJkeKOSk5NTVFSUn5//u9/9js1mOzo6njt3zsfHByH0wQcfvPzyy8uXLx8YGEAIEQTh5OS0cOHCqVOnMjuXDrRHEIT2hRg/WVlZLS0tuKNgDvb479279/HHH+/du5fP5yun+/v7x8TEPH78eMeOHbhio/nrX//q6+s7c+bMUffu2bPn1q1baWlpOjkXE+2RJJmcnDx9+nQej2dhYbFz50561+DgYEJCgqurq0AgmDVrVm5uLkLo2LFjIpFIKBSeO3du2bJlEonE2dn5zJkz1CFXr16dP3++UCiUSCQzZ87s7u4eqxwVXLt2zdXVlSCIo0ePqj5jeno6n8+3s7PbvHmzo6Mjn8/39/e/fv06Qig6OprL5To4OFBlvvfeeyKRiCCItra2mJiY2NjYuro6giA8PT0ZXDRji//SpUsSiWT//v06r8tYpKenkyQZFBQ0cldSUtK0adNOnjx5+fLlkXtJkjxy5MhLL73E4/GsrKxWrlx5+/ZtNN59pekthBDq7+8vLy+fPXv2WBmsrKwWLVqUlpammxcEUgkqPnI8du/eTRDEZ5991tHRIZPJMjMzEUIVFRUkSe7YsYPH4xUUFHR0dOzatYvFYt24cYM6BCH0/fffd3V1tbS0LFy4UCQS9ff39/b2SiSSw4cPy+Xy5ubmVatWtba2qihHBY8ePUIIZWRk0EGOekaSJKOiokQiUU1NzfPnz6urq+fNmycWix8+fEiS5Lp16+zt7ekyk5OTEUJUSKGhoVKpdNyLQ4EQys3NVTMzlviLi4vFYnFiYqJGQZIkGRYWFhYWNm62qKgoJycn5RQPD48ZM2YMyyaVSh88eECS5A8//MBisaZMmdLb20uSZElJSXBwMJUnISGBy+WeOnWqs7OzsrLS19fXxsamublZ9VVicAs9ePAAITR79uzFixc7ODjweDwvL6+jR48ODQ3ReeLj4+m7neKDDz6YNGnSuBdk5HXT+Lknl8tTU1P/8Ic/bN++3dLSUiAQWFtbU7ueP39+7NixkJCQ0NBQS0vLjz76iMPhZGdn08f6+/tLJBJbW9uIiIhnz549fPiwvr6+u7vb29ubz+fb29ufPXvWxsZm3HLUZ+QZqXQ2m039H50xY8axY8d6enqYla9v9Bf/ihUruru7P/74Yz1EPQrPnj178OCBVCodK8OCBQu2bdtWX1//l7/8RTldLpcfOXJk1apV69evt7CwmDlz5ueff97W1nb8+HE6z8irxOwW6u3tRQjZ2tru37+/urr6yZMnK1eu3Lp169/+9jc6D/V2V1VVxew6KKOx9u7duyeTyZYsWTJy1507d2QyGfViihASCAQODg5U92AYXC4XIaRQKDw8POzs7NavX79nz576+npNy1Ef+owjd82dO1coFGpZvr4x9fhbWlpIkhQKhSryJCUlTZ8+PTMz89q1a3RidXV1b2/v3Llz6ZR58+ZxuVyqmz0M+ioxu4Wob0Le3t7+/v7W1tYWFhZ79+61sLBQ1jlVhSdPnoxb5XHRWHvUT2NsbW1H7nr27BlC6KOPPqLHPRoaGmQymYrSBALBlStXAgIC9u/f7+HhERERIZfLGZSjJTwer7W1VX/l6xvjj//58+fot5t7LPh8fnZ2NkEQGzdulMvlVCL1Td/c3Fw5p6WlZU9Pj4qimN1Cjo6OCKG2tjY6hcvlurm51dXV0SkCgYCujpZorD3qI1VfX9/IXZQgU1NTlTu1w36zNBJvb+8LFy40NTXFxcXl5uampKQwK4cxCoWis7PT2dlZT+XrG5OIn7pllcemR4X6dWltbe2+ffuoFEtLS4TQMKWNW19mt5C5ufnUqVNramqUEwcGBiwsLOjN/v5+ujpaorH2fHx8WCzW1atXR+5ycXHh8/kaTXBpamqiqmpra3vw4EFfX9+amhoG5WhDaWkpSZJ+fn4IITabPWq/zpgxifjt7OwIglBnBG/fvn1eXl4VFRXUpo+Pj7m5+U8//URnuH79en9//yuvvKKiEMa3UHh4eEVFxf3796lNmUzW0NCgPORAVcHe3l7TkkeisfZsbW1DQ0MLCgqysrK6u7srKyvp3jCfz9+wYcOZM2eOHTvW3d09ODjY2Nj466+/qiitqalp8+bNt2/f7u/vr6ioaGho8PPzY1COpgwNDXV0dAwMDFRWVsbExLi6ukZGRiKEPD09nz59WlRUpFAoWltbGxoa6EOsra2bmprq6+t7enqw39/ax19SUmLIMQahUOjh4aHOb/mpnqeZmRm9GRsbW1hYePr06e7u7qqqqi1btjg6OkZFRakuZKxbKCIiwt7efqypatu3b3dzc4uMjHz48GF7e3tcXJxcLlf+/ENVYawBQM1QfiirOcbQ09OzadOmSZMmmZubBwQEJCQkIIScnZ1//vnnvr6+uLg4V1dXNptNqbS6ujozM5N6Q506dWpdXd3x48clEglCyM3N7bvvvvP397eysjIzM5s8efLu3bsHBgZIkhy1HBUhZWRkUONaQqEwKChIxRnv3r0bFRXF4XCcnJzYbLZEIlm5cmVdXR1VTnt7+2uvvcbn893d3d9//31q6NLT0/Phw4c3b950c3MTCAQBAQHUB24VIA3HGAwf/8WLF8VicVJSkvpBUjAeY4iOjuZwODKZjNosLCykPnva2Nhs3bp12OE7d+6kxxiGhoaSk5OnTp3K4XCsrKxCQkLu3LlDkqTqqzTWLRQSEoIQSkhIGCvyR48erV271srKisfjzZ8/v6SkRHnvihUrnJyclEcdGI8xMNGeqRMVFWVtba3XU2iqPY0wQPwqYKy92tpaNpt96tQpvYWmFoODgwsXLszKymJwbFtbG5/PT0lJUU403PjexGDcl34jxyTil8vl33zzTW1tLfV9wtPTMzExMTExkRpGw8Lg4GBRUVFPT09ERASDw/fs2TN79uzo6GiEEEmSTU1N165du3fvHrNgTEZ7t2/fJsaG2aUE9MrTp0+pudQbN26kUuLj41evXh0REYFr2nRpaenZs2dLSkpUjzSOypEjR27dunXx4kUOh4MQOnfuHDWXWvkXGJqh/BB8Efqc8fHx1AjslClT8vPz9XQWpLc+p2HiV4GafU4VfPPNN3FxcbqKxzAUFRUdOHCA+hjBjJHXjSCVZoXm5eWFh4eTE+6HZIaHIIjc3FxYIxCgGXndTKbPCQATDNAeAOABtAcAeADtAQAeQHsAgAnlj57q/K4eAABmDBtjGMWHCBSoPeHh4TExMQsWLMAdiO5JTU1FCG3btg13ICYGdd2UGUV7E3JUysCEh4cvWLBgQl5JaoRqQlZNr4wcEYX3PQDAA2gPAPAA2gMAPID2AAAPoD0AwANz7ZWXl7/00kssFosgCHt7+6SkJB2GNSrKrlEODg7DnKUAowI8wMZn5Ni6Rr9KeuONNxBCHR0dGh2lDVKp1MLCwmCnYwbS55oReFF/zQjaA+z58+d0ekJCQmBgYHd3N7VJeYAhhIqLi5UPV14T3sCEhIRMnz69vLxcoVA0NTUFBQVVVVWRJJmWlrZo0SL6Vh8aGqI9wCbmmhGGd64ycnRyQQxzVcEDTDXGrj3szlXGhk4uCJarCh5gw9Cl9ozBeeu//uu/ZsyYYWFhwefzZ86c+c033yCENm3aRPXLpVIptejqhg0bhEKhhYXF+fPnRzWL+vTTT4VCoVgsbmlpiY2NdXJyunPnjg6vFRrb2kr9C2JafmDgATZKxWi0f98zgPOW6ve9/Pz8PXv2PH36tL293c/Pj+6Ih4aGmpmZPX78mM755ptvnj9/nhzPt+yDDz7IyMhYtWrVP//5T/UvC1LjfU+FtZX6F8TwfmDgAYZweYCpA0bnrbCwsE8++cTKysra2jooKKi9vZ0yCdmyZcvg4CB9uu7u7hs3bixfvnxcs6hDhw5t3br17NmzXl5eOoxTHWsrNTEJPzDwABuJft/38DpXUWu5Ud+F/+Vf/mXatGlffPEFSZIIoZycnIiICDMzM334jamDRtZW6mO0fmDgATYSnN9a9OFc9fXXXy9evNjW1pbH43344Yd0OkEQmzdvvn///vfff48Q+vLLL//1X/8VMTWL0h5m1lbqYJx+YOABNhJs2tOtc9U//vGP1NTUhw8fhoSEODg4XL9+vaur6/Dhw8p5IiMj+Xz+yZMn79y5I5FI3NzcEFOzKO1hZm01LkbrBwYeYCPBpj3dOlf9z//8j0gkqqqqUigU7777roeHB5/PJwhCOY+VlVV4eHhRUVFKSso777xDJRrYb4xGtbUV4wtitH5g4AE2EoNqTx/OWwqF4smTJ6WlpSKRyNXVFSF0+fLl58+f19bWjnwl2LJlS19fX3FxcWBgIJViAL+xUVFtbaXRBTEJPzDwABsF5YeyRmMM5eXl3t7eLBYLIeTg4LB//359O1f99a9/VfGhrLCwkCTJuLg4a2trS0vL1atXHz16FCEklUqpb+4Uc+bMiY+PV67IqGZRhw8fpvoVLi4uDKxzkBpjDGNZW6l/QZqbmw3vBwYeYKbnAYbXuYpm+fLl9+/f1/dZ1NGeTjD8VQUPMJP0AMPlXEV3VisrK6nnAJYw9ITR+oGBB5hqjH0+p06Ii4urra29e/fuhg0b6A9ogL4BD7BxUH4I6q/Pide5avfu3SwWy8XFhZpEZgCQQfqcWK4qeIAxAzzADAR4gAHDAA8wADAWQHsAgAfQHgDgAbQHAHgYxY8hLy/P8HFMPAwwIRsL1KQquEk0pbGxcfj8b+WPnuBABAD6Q9UYA2BaTOCRjBcBeN8DADyA9gAAD6A9AMADaA8A8ADaAwA8gPYAAA+gPQDAA2gPAPAA2gMAPID2AAAPoD0AwANoDwDwANoDADyA9gAAD6A9AMADaA8A8ADaAwA8gPYAAA+gPQDAA2gPAPAA2gMAPID2AAAPoD0AwANoDwDwANoDADyA9gAAD6A9AMADaA8A8ADaAwA8gPYAAA+gPQDAA2gPAPAA2gMAPIzitw4YLSdOnHj69Klyyrlz5x48eEBvbtiwwc7OzuBxAUwAz2dTYvPmzf/xH//B4/FG7lIoFFZWVs3NzWw2/D81DaDPaUqsXbsWIdQ3GmZmZm+++SYIz4SA554pQZKkk5PTr7/+OureH374YcGCBQYOCWAMPPdMCYIg1q1bx+VyR+6aPHmyn5+f4UMCGAPaMzHWrl3b398/LJHL5f75z38mCAJLSAAzoM9pekydOvXevXvDEisrK2fOnIklHoAZ8NwzPdavX8/hcJRTPD09QXgmB2jP9Fi/fv3AwAC9yeFwNmzYgDEegBnQ5zRJZs+eXVlZSbUdQRB1dXXu7u64gwI0A557Jsnbb79tZmaGECII4pVXXgHhmSKgPZNk7dq1Q0NDCCEzM7O3334bdzgAE0B7Jomjo+Orr75KEMTQ0NDq1atxhwMwAbRnqrz11lskSS5evNjBwQF3LAAjSF0TFhaGu04AoHt0rhS9TL318/Pbtm2bPko2JOHh4TExMcY8QzI1NfXf/u3fRCIRgwMRQhOgjQxDWVlZWlqazovVi/acnZ3XrFmjj5INSXh4+IIFC4y5IgEBAZMnT2ZwYH5+PkLImKtmbOhDe/C+Z8IwEx5gJID2AAAPoD0AwANoDwDwANoDADwYkfY2bdokFosJgrh16xbuWBhy8eJFCwuLCxcu4A5Ej1y+fDk+Pv7s2bMeHh4EQRAE8dZbbylnWLp0qVgsNjMz8/b2vnnzpoHDUygUBw4c8PT05HK5lpaWPj4+9fX158+fP3z48ODgoIGDUY0Rae/kyZMnTpzAHYVWkBP9RyGffPJJenr6rl27QkND79+/L5VKJ02adPr06a+//prO8+233+bn5wcGBlZXV/v6+ho4wvDw8C+//PKrr76SyWT//Oc/pVJpb29vUFAQn89fsmRJZ2engeNRgRFpbwKwYsWKrq6uwMBAPZUvl8v9/f31VPi4HDp0KCcnJy8vTywW04np6eksFisqKqqrqwtXYDQ5OTlFRUX5+fm/+93v2Gy2o6PjuXPnfHx8EEIffPDByy+/vHz5cuWfPuLFuLQHK46oJisrq6WlBcup79279/HHH+/du5fP5yun+/v7x8TEPH78eMeOHVgCU+avf/2rr6/vWD/h37Nnz61bt/QxSs4MzNojSTI5OXn69Ok8Hs/CwmLnzp30rsHBwYSEBFdXV4FAMGvWrNzcXITQsWPHRCKRUCg8d+7csmXLJBKJs7PzmTNnqEOuXr06f/58oVAokUhmzpzZ3d09Vjn64Nq1a66urgRBHD16VHWo6enpfD7fzs5u8+bNjo6OfD7f39//+vXrCKHo6Ggul0tPj37vvfdEIhFBEG1tbTExMbGxsXV1dQRBeHp6IoQuXbokkUj279+vpxopk56eTpJkUFDQyF1JSUnTpk07efLk5cuXR+4lSfLIkSMvvfQSj8ezsrJauXLl7du30XhNyaDV+vv7y8vLZ8+ePVYGKyurRYsWpaWlGcurgc5niIaFhYWFhamZeffu3QRBfPbZZx0dHTKZLDMzEyFUUVFBkuSOHTt4PF5BQUFHR8euXbtYLNaNGzeoQxBC33//fVdXV0tLy8KFC0UiUX9/f29vr0QiOXz4sFwub25uXrVqVWtrq4pyxgUhlJubq1HdHz16hBDKyMigazdqqCRJRkVFiUSimpqa58+fV1dXz5s3TywWP3z4kCTJdevW2dvb02UmJycjhKi6hIaGSqVSeldxcbFYLE5MTNQoSFLDNqLw8PCYMWPGsESpVPrgwQOSJH/44QcWizVlypTe3l6SJEtKSoKDg6k8CQkJXC731KlTnZ2dlZWVvr6+NjY2zc3Nqq8Pg1aj1safPXs29dsOHo/n5eV19OjRoaEhOk98fDx9g6kPpXyNDlEHnNqTyWRCofD111+nU6h/exUVFXK5XCgURkRE0Dl5PN67775L/tZgcrmc2kXJ9d69e7/88gtCqLi4WPkUKsoZF11pb2SoJElGRUVZWFjQB964cQMhtHfvXlIT7TFGU+319vYSBBEYGDgsndYeSZKxsbEIoa1bt5JK2pPJZObm5vT1J0nyxx9/RAhR/y/Guj7MWq2qqgoh9Prrr//3f/93e3t7Z2fnX/7yF4TQ6dOn6TxffPEFQujLL79Uv+6k3rSHs8957949mUy2ZMmSkbvu3Lkjk8mot2SEkEAgcHBwoPoqw6AWilUoFB4eHnZ2duvXr9+zZ099fb2m5RgAOtSRu+bOnSsUCnEFNi4tLS0kSQqFQhV5kpKSpk+fnpmZee3aNTqxurq6t7d37ty5dMq8efO4XC7VwR4GfX2YtRplU+Ht7e3v729tbW1hYbF3714LC4vjx4/TeagqPHnyZNwqGwCc2mtsbEQI2drajtz17NkzhNBHH31E/EZDQ4NMJlNRmkAguHLlSkBAwP79+z08PCIiIuRyOYNycMHj8VpbW3FHMTrPnz9Hv93cY8Hn87OzswmC2Lhxo1wupxKpb/rm5ubKOS0tLXt6elQUxazVHB0dEUJtbW10CpfLdXNzq6uro1MEAgFdHezg1B71xayvr2/kLkqQqampys/osrIy1QV6e3tfuHChqakpLi4uNzc3JSWFWTmGR6FQdHZ2Ojs74w5kdKhbdtyx6QULFmzfvr22tnbfvn1UiqWlJUJomNLGrSmzVjM3N586dWpNTY1y4sDAgIWFBb1JLelNVQc7OLXn4+PDYrGuXr06cpeLiwufz9dogktTUxN13W1tbQ8ePOjr61tTU8OgHCyUlpaSJEkZKrDZ7FH7pRixs7MjCEKdEbx9+/Z5eXlVVFRQmz4+Pubm5j/99BOd4fr16/39/a+88oqKQhi3Wnh4eEVFxf3796lNmUzW0NCgPORAVcHe3l7TkvUBTu3Z2tqGhoYWFBRkZWV1d3dXVlbSXXM+n79hw4YzZ84cO3asu7t7cHCwsbFxLP8diqamps2bN9++fbu/v7+ioqKhocHPz49BOQZjaGioo6NjYGCgsrIyJibG1dU1MjISIeTp6fn06dOioiKFQtHa2trQ0EAfYm1t3dTUVF9f39PTo1AoSkpKDDPGIBQKPTw8qHcE1VA9T2r9QmozNja2sLDw9OnT3d3dVVVVW7ZscXR0jIqKUl3IWK0WERFhb28/1lS17du3u7m5RUZGPnz4sL29PS4uTi6XU19cKKgqGMsa3jr/eqPRN7Senp5NmzZNmjTJ3Nw8ICAgISEBIeTs7Pzzzz/39fXFxcW5urqy2WxKpdXV1ZmZmdTr8tSpU+vq6o4fPy6RSBBCbm5u3333nb+/v5WVlZmZ2eTJk3fv3j0wMECS5KjlqBMb0vA7Z0ZGBjUuJxQKg4KCVIR69+7dqKgoDofj5OTEZrMlEsnKlSvr6uqoctrb21977TU+n+/u7v7+++9TY56enp4PHz68efOmm5ubQCAICAhobm6+ePGiWCxOSkpSP0gKBmMM0dHRHA5HJpNRm4WFhVKpFCFkY2NDfdtUZufOnfQYw9DQUHJy8tSpUzkcjpWVVUhIyJ07d0iSVH19xmq1kJAQhFBCQsJYcT569Gjt2rVWVlY8Hm/+/PklJSXKe1esWOHk5KQ86qAOE3CMwcjRVHsaERUVZW1trafCx4VBG9XW1rLZ7FOnTukpJDUZHBxcuHBhVlYWg2Pb2tr4fH5KSoqmB07AMYYXHGObVq8aT0/PxMTExMTE3t5eXDEMDg4WFRX19PREREQwOHzPnj2zZ8+Ojo7WeWDMAO0B6hIfH7969eqIiAhc06ZLS0vPnj1bUlKieqRxVI4cOXLr1q2LFy8Os3DCCGgPA7t27crOzu7q6nJ3dy8oKMAdjgbs378/Ojr64MGDWM6+ZMmSr776isFawOfOnevr6ystLbWystJHYMzQyxqBgGoOHDhw4MAB3FEwZOnSpUuXLsUdhWYEBwcHBwfjjmI48NwDADyA9gAAD6A9AMADaA8A8KCXby2NjY15eXn6KNnAGOGsa51ATa2aGG1kAPR1G+h8tB48wIAJic6Vopc+J8wpM3ImzLw/w6CnNX7gfQ8A8ADaAwA8gPYAAA+gPQDAA2gPAPAA2gMAPODRnrKDFAWXy7Wzs1u8eHFycnJHRweWqICxMGbfr8TExBkzZkgkEh6P5+np+eGHH9K/7k1KSiL+L9San0ZiCYZHe7SDFLU289DQUEtLS15enru7e1xcnLe3t/LKVgBejNz368qVK1u3bq2vr29raztw4EBaWtrq1atVH2IklmBG0eckCMLS0nLx4sXZ2dl5eXlPnjyhzLRwx6UvdGLlZRg/MOP3/TI3N6cWvxGLxWvWrAkJCbl06RK1OD9CaNgCM5RxADIOSzCj0J4yYWFhkZGRLS0tn3/+Oe5Y9IVOrLwM4AdmEr5fxcXF9JKECCEbGxuEkDpLj2O3BDM67SGEqGUqS0pKkNE7gZFjGFypb+VlzH5gxu/7NZLHjx8LBAJ3d/dxc+K3BNP55Df15wrS73vDoNTi4uJCYnUCQ2rM51RhcKW+nZDh/cDUbCPj9/0axrNnz8RicXR0NLW5b98+Z2dnS0tLDoczZcqU4ODgH3/8UTm/mpZgE3B9zrG0R5Ik9QaI1wlsXO2pNrjSSHsG9gNTp41MwvdrGLt37542bVp3dze1Sa0m3NPT09fXV1ZWNmfOHIFA8Msvv9D51bQEe4HW53z27BlJkhKJxMidwDQyuFIfI/EDMwnfL2UKCwvz8vK++eYb+rOQi4vLnDlzzM3NuVyun59fdna2XC6n1E6B1xLMGLV39+5dhJCXl5eRO4ExM7hSB2PwAzMJ3y+anJycQ4cOlZaWTpkyZaw8M2fONDMzo+4uCryWYMaovUuXLiGEli1bZuROYMwMrsbFSPzATML3iyIjI+P06dNXrlyZPHmyimxDQ0NDQ0PK/03wWoIZnfaam5tTU1OdnZ03btxo5E5gqg2uGFt5GYkfmEn4fpEkGRcXV1VVVVRUNOxJixB64403lDepLzcLFiygU/BagmHWHkmSvb29lC9Ma2trbm7uq6++amZmVlRUJJFIjNwJTLXBlfpWXsgo/cBMwverpqbm008/PXHiBIfDUZ47lpKSghB6/PhxTk5OZ2enQqEoKyvbtGmTq6vrli1b6MMxW4Lp/OuNOt/Qzp8/P2vWLKFQyGE4CtMAACAASURBVOVyWSwW+m1qy/z58xMTE9vb2+mcGJ3AkBpjDGMZXJGaWHkZ3g9MzW/Rxu/7VVVVNepdnZycTJJkbGysVCoViURsNtvZ2fmdd95pampSPlxNS7AJOMZg5KijPZ1geD8wNdtoAvh+qUB9S7AXaIzhBQT7nPpRmQC+XyrAbgkG2gNUYdK+XyowBksw0B5mjN8PzER9v1RgJJZg4AGGGZPwAzNF3y8VGIklGDz3AAAPoD0AwANoDwDwANoDADzo5VtLeXn5uOvVmASpqan5+fm4o9A95eXlCKGJ0UYGQJ2JdQwgSF3/YP7IkSMT1bbO2Pj+++99fHxwTQV+0dD5f2Hdaw8wGARB5ObmrlmzBncgABPgfQ8A8ADaAwA8gPYAAA+gPQDAA2gPAPAA2gMAPID2AAAPoD0AwANoDwDwANoDADyA9gAAD6A9AMADaA8A8ADaAwA8gPYAAA+gPQDAA2gPAPAA2gMAPID2AAAPoD0AwANoDwDwANoDADyA9gAAD6A9AMADaA8A8ADaAwA8gPYAAA+gPQDAA2gPAPAA2gMAPID2AAAPoD0AwANoDwDwAL6zpsTbb79dUVFBbz569GjSpElCoZDa5HA4xcXFkydPxhQdoBls3AEAGjB9+vRTp04pp3R1ddF/z5gxA4RnQkCf05RYv349QRCj7uJwOJGRkYYNB9AK6HOaGHPnzr158+bIViMI4v79+1OmTMERFMAEeO6ZGG+//baZmdmwRBaL5efnB8IzLUB7JkZERMTQ0NCwRBaL9fbbb2OJB2AMaM/EsLOzW7Ro0bBHH0mSq1atwhUSwAzQnunx1ltvKb/vmZmZ/eEPf7Czs8MYEsAA0J7pERoaymb/7+AQSZLr16/HGA/ADNCe6SGRSJYtW0bLj81mBwUF4Q0JYABozyRZv3794OAgQojNZgcHB0skEtwRARoD2jNJ/vSnP1FTyQYHB9etW4c7HIAJoD2ThM/nh4aGIoREItEf//hH3OEATNBqPmdeXp6u4gA0xdnZGSE0b968c+fO4Y7lxcXf359qCCaQWqDTWgCA6ZGbm8tYPtr2ObU5tykSFhYWFhaGO4r/T1JS0sDAgK5Ky83NRdr9L37R0FI78L5nwsTFxY2c2wmYCqA9E0Z5hB0wOUB7AIAH0B4A4AG0BwB4AO0BAB4Mqr1NmzaJxWKCIG7dumXI847F0NBQamqqv7+/Xs9y8eJFCwuLCxcu6PUshufy5cvx8fFnz5718PAgCIIgiLfeeks5w9KlS8VisZmZmbe3982bNw0ZW2Ji4owZMyQSCY/H8/T0/PDDD3t7e6ldSUlJxP/Fx8cHIXT+/PnDhw9Ts2QNg0G1d/LkyRMnThjyjCqora39/e9/v337dplMptcTaT8QZIR88skn6enpu3btCg0NvX//vlQqnTRp0unTp7/++ms6z7fffpufnx8YGFhdXe3r62vI8K5cubJ169b6+vq2trYDBw6kpaWtXr1a9SFBQUF8Pn/JkiWdnZ2GCfIF7XP+/PPPf/nLX7Zs2TJ79mx9n2vFihVdXV2BgYF6Kl8ul+v70T2MQ4cO5eTk5OXlicViOjE9PZ3FYkVFRSkvW4gLc3PzqKgoa2trsVi8Zs2akJCQS5cuPXr0iNp76tQp5SHyX375hUr/4IMPXn755eXLlw8MDBggSENrb6wl7gzMyy+/fPbs2XXr1vF4PNyxaEtWVlZLS4vBTnfv3r2PP/547969fD5fOd3f3z8mJubx48c7duwwWDBjUVxcrDzrwMbGBiGkTgdnz549t27dSktL02Nwv6F37ZEkmZycPH36dB6PZ2FhsXPnTnrX4OBgQkKCq6urQCCYNWsWNafp2LFjIpFIKBSeO3du2bJlEonE2dn5zJkz1CFXr16dP3++UCiUSCQzZ87s7u4eqxwj4dq1a66urgRBHD16FKmsXXp6Op/Pt7Oz27x5s6OjI5/P9/f3v379OkIoOjqay+U6ODhQZb733nsikYggiLa2tpiYmNjY2Lq6OoIgPD09EUKXLl2SSCT79+/XU43S09NJkhz117pJSUnTpk07efLk5cuXR+4lSfLIkSMvvfQSj8ezsrJauXLl7du3VV8TpKPGffz4sUAgcHd3HzenlZXVokWL0tLSDPGmoOV8tnHnc+7evZsgiM8++6yjo0Mmk2VmZiKEKioqSJLcsWMHj8crKCjo6OjYtWsXi8W6ceMGdQhC6Pvvv+/q6mppaVm4cKFIJOrv7+/t7ZVIJIcPH5bL5c3NzatWrWptbVVRjjr87ne/e/nll9WvMoP5nFRXJyMjg74go9aOJMmoqCiRSFRTU/P8+fPq6up58+aJxeKHDx+SJLlu3Tp7e3u6zOTkZIQQVf3Q0FCpVErvKi4uFovFiYmJGgVJqj2f08PDY8aMGcMSpVLpgwcPSJL84YcfWCzWlClTent7SZIsKSkJDg6m8iQkJHC53FOnTnV2dlZWVvr6+trY2DQ3N6u+Jto0LsWzZ8/EYnF0dDS1uW/fPmdnZ0tLSw6HM2XKlODg4B9//FE5f3x8PH2Lqkad+1/V4YyPVOfcMplMKBS+/vrrdAr1/6yiokIulwuFwoiICDonj8d79913yd9aQi6XU7soud67d4/qlxcXFyufQkU56oBLeyNrR5JkVFSUhYUFfeCNGzcQQnv37iU10R5j1NFeb28vQRCBgYHD0mntkSQZGxuLENq6dSuppD2ZTGZubk43E0mSP/74I0KI+h8x1jXRsnEpdu/ePW3atO7ubmrz4cOHN2/e7Onp6evrKysrmzNnjkAg+OWXX+j8X3zxBULoyy+/HLdkLbWn3z7nvXv3ZDLZkiVLRu66c+eOTCajPu8ihAQCgYODA9UJGQaXy0UIKRQKDw8POzu79evX79mzp76+XtNyjBO6diN3zZ07VygUGlVdWlpaSJKk3VdGJSkpafr06ZmZmdeuXaMTq6ure3t7586dS6fMmzePy+VSneph0NdE+8YtLCzMy8v75ptv6M9CLi4uc+bMMTc353K5fn5+2dnZcrmcUjsFVbsnT56ofxZm6Fd7jY2NCCFbW9uRu549e4YQ+uijj+hhloaGBtVvwwKB4MqVKwEBAfv37/fw8IiIiJDL5QzKMSF4PF5rayvuKP6X58+fI4RUf6Di8/nZ2dkEQWzcuFEul1OJ1Id7c3Nz5ZyWlpY9PT0qitKycXNycg4dOlRaWqpixe6ZM2eamZndvXuXThEIBOi3muoV/WqP+hTW19c3chclyNTUVOWncFlZmeoCvb29L1y40NTUFBcXl5ubm5KSwqwck0ChUHR2djL/WbQeoO7LcQegFyxYsH379tra2n379lEplpaWCKFhShu3dto0bkZGxunTp69cuaLam2loaGhoaEj5v0l/fz/6raZ6Rb/a8/HxYbFYV69eHbnLxcWFz+drNMGlqamppqYGIWRra3vw4EFfX9+amhoG5ZgKpaWlJEn6+fkhhNhs9qj9UgNjZ2dHEIQ6I3j79u3z8vKi3QJ9fHzMzc1/+uknOsP169f7+/tfeeUVFYUwa1ySJOPi4qqqqoqKioY9aRFCb7zxhvIm9eVmwYIFdApVO3t7e41OygD9as/W1jY0NLSgoCArK6u7u7uysvL48ePULj6fv2HDhjNnzhw7dqy7u3twcLCxsfHXX39VUVpTU9PmzZtv377d399fUVHR0NDg5+fHoBxjZmhoqKOjY2BgoLKyMiYmxtXVlXL28vT0fPr0aVFRkUKhaG1tbWhooA+xtrZuamqqr6/v6elRKBQlJSX6G2MQCoUeHh7Uq4RqqJ4nPcjG5/NjY2MLCwtPnz7d3d1dVVW1ZcsWR0fHqKgo1YWM1bgRERH29vajTlWrqan59NNPT5w4weFwlOeOpaSkIIQeP36ck5PT2dmpUCjKyso2bdrk6uq6ZcsW+nCqdjNnztTkwjCC8VcaUr3vPD09PZs2bZo0aZK5uXlAQEBCQgJCyNnZ+eeff+7r64uLi3N1dWWz2ZRKq6urMzMzqZfdqVOn1tXVHT9+nFp80s3N7bvvvvP397eysjIzM5s8efLu3bupFRNGLUd1VGVlZa+++qqjoyN1ERwcHPz9/a9evTpulTX9zpmRkUGNywmFwqCgIBW1u3v3blRUFIfDcXJyYrPZEolk5cqVdXV1VDnt7e2vvfYan893d3d///33qWFST09P6qudm5ubQCAICAhobm6+ePGiWCxOSkpSP0gKNccYoqOjORyOTCajNgsLC6VSKULIxsaG+rapzM6dO+kxhqGhoeTk5KlTp3I4HCsrq5CQkDt37pAkqfqajNW4ISEhCKGEhISREVZVVY16qycnJ5MkGRsbK5VKRSIRm812dnZ+5513mpqalA9fsWKFk5PT0NDQuJdCnftf1eGMj9T+3KaIXtdroaZB6anwcVFTe7W1tWw2e9i0LMMzODi4cOHCrKws3Rbb1tbG5/NTUlLUyazl/f+Czuc0Wgw5j54Znp6eiYmJiYmJ9C8DDM/g4GBRUVFPT09ERIRuS96zZ8/s2bOjo6N1W+yoTEzt3b59mxgbnTfYi0Z8fPzq1asjIiJwTZsuLS09e/ZsSUmJ6pFGTTly5MitW7cuXrzI4XB0WOxYTEzteXl5qXjW5+Tk4A5wFHbt2pWdnd3V1eXu7l5QUIA7nHHYv39/dHT0wYMHsZx9yZIlX331FT3BVSecO3eur6+vtLTUyspKh8WqABa6MhYOHDhw4MAB3FFowNKlS5cuXYo7Cp0RHBwcHBxsyDNOzOceABg/oD0AwANoDwDwANoDADxo+60lNTU1Pz9fJ6GYBOXl5QihcRfeMUWouVQTsmrGCTz3AAAP2j73tm3btmbNGp2EYhJQj4UJ+ajPy8sLDw+fkFXTE1ou/AXPPQDAA2gPAPAA2gMAPID2AAAPoD0AwAMe7Smb11BwuVw7O7vFixcnJyd3dHRgiQrQCPAh0hbGv7oltf7drlQqpZaCpRYp+fvf/x4ZGUkQhKOjo6ZrDxsMvf5uHS9q/m6dIiEhITAwkF5wlvIhQiNWLlZel9qQLFq0KDMzs729vbu7Ozc3l8Ph/PGPf6R20Uun0Xh7e1O70tLSFi1a1NHRoeZZtLz/jaLPSRCEpaXl4sWLs7Oz8/Lynjx5Qnn34I7L0OjEUcgAtkTgQ6QTjEJ7yoSFhUVGRra0tHz++ee4YzE0OnEU0rctEfgQ6Qqj0x5CiFoVr6SkBJmsVxE5hueO+o5CRmtLBD5EOoNxb1X7/i79vjcMSi0uLi6kcXgVKaPm+54Kzx31XU0MbEsEPkQUE8SHSDVjaY8kSeoN0Ei8ipRRR3uqPXc00p4hbYnAh4higvgQMePZs2ckSUokEhP1KtLIc0d9jMGWCHyIdIgxao8yhfHy8jJRryJmnjvqgN2WCHyIdIgxau/SpUsIoWXLlpmoVxEzz51xMQZbIvAh0iFGp73m5ubU1FRnZ+eNGzeaqFeRas8dxo5CxmBLBD5EOgSz9kiS7O3tpXwnWltbc3NzX331VTMzs6KiIolEYqJeRao9d9R3FELGZ0sEPkS6hPFXGlKL7zznz5+fNWuWUCjkcrksFgv9NrVl/vz5iYmJ7e3tdE6MXkWjouYYw1ieO6QmjkIGtiUCHyIK8CEyUgw5n9PAtkTgQ0SCDxFAY4S2ROBDpCtAe4DGgA+RTgDtGSlGbksEPkTaAz5ERorx2xKBD5GWwHMPAPAA2gMAPID2AAAPoD0AwANoDwAwwXhUnjTAj+oBwLjRZl6LVmMM+l71BFBNeHh4TEyM8hx8wMBosyQcAY8v04UgiNzc3BfKg20iAe97AIAH0B4A4AG0BwB4AO0BAB5AewCAB9AeAOABtAcAeADtAQAeQHsAgAfQHgDgAbQHAHgA7QEAHkB7AIAH0B4A4AG0BwB4AO0BAB5AewCAB9AeAOABtAcAeADtAQAeQHsAgAfQHgDgAbQHAHgA7QEAHkB7AIAH0B4A4AG0BwB4AO0BAB5AewCAB9AeAOABtAcAeADtAQAetPKdBQxMQ0PD4OCgcsqTJ0/u379Pb06ePJnP5xs8LoAJ4DtrSqxYseLixYtj7eVwOE+ePLGysjJkSABjoM9pSkRERIy1i8ViLV26FIRnQoD2TIlVq1aN1aUkSfKtt94ycDyANoD2TAmRSPSnP/2Jw+GM3MXj8f70pz8ZPiSAMaA9E2PdunUDAwPDEjkczqpVq0QiEZaQAGaA9kyM5cuXm5ubD0tUKBTr1q3DEg/AGNCeicHlclevXs3lcpUTJRLJH/7wB1whAcwA7Zkeb775Zn9/P73J4XDWrl07TI2A8QPje6bH0NCQg4NDa2srnXL16tXf//73GEMCGADPPdODxWKtW7eO/tppa2sbEBCANySAAaA9k2Tt2rUKhQIhxOVyIyMjWSxoR9MD+pwmCUmSU6ZMefjwIULop59+euWVV3BHBGgM/L80SQiCePvttxFCHh4eIDwTRavfMaxevVpXcQCa0t3djRDi8/nQChjZvn37ggULmB2r1XOvoKCgsbFRmxJMjvLy8vLyctxRIISQRCKxtLR0cXHRVYGNjY0FBQW6Ku1FoKCg4NGjR4wP1/b3e9u2bVuzZo2WhZgQ1EMmPz8fdyAIIXT58mUdDqnn5eWFh4cbSdVMAoIgtDkc3vdMGJjLYtKA9gAAD6A9AMADaA8A8ADaAwA8GFR7mzZtEovFBEHcunXLkOcdSWJi4owZMyQSCY/H8/T0/PDDD3t7e/V0rosXL1pYWFy4cEFP5ePi8uXL8fHxZ8+e9fDwIAiCIIhhi1YsXbpULBabmZl5e3vfvHnTkLGpaN+kpCTi/+Lj44MQOn/+/OHDh4ctA6dXDKq9kydPnjhxwpBnHIsrV65s3bq1vr6+ra3twIEDaWlp+huhnpCz9j755JP09PRdu3aFhobev39fKpVOmjTp9OnTX3/9NZ3n22+/zc/PDwwMrK6u9vX1NWR4DNo3KCiIz+cvWbKks7PTMEG+oH1Oc3PzqKgoa2trsVi8Zs2akJCQS5cuaTNOqoIVK1Z0dXUFBgbqo3CEkFwu9/f311Pho3Lo0KGcnJy8vDyxWEwnpqens1isqKiorq4uQwYzKqrb99SpU6QSv/zyC5X+wQcfvPzyy8uXLx+5Koc+MLT2tByO1BXFxcVmZmb0po2NDUJIJpPhi4g5WVlZLS0tBjvdvXv3Pv7447179w5bMc3f3z8mJubx48c7duwwWDBjwbh99+zZc+vWrbS0ND0G9xt61x5JksnJydOnT+fxeBYWFjt37qR3DQ4OJiQkuLq6CgSCWbNm5ebmIoSOHTsmEomEQuG5c+eWLVsmkUicnZ3PnDlDHXL16tX58+cLhUKJRDJz5kxqTuOo5WjE48ePBQKBu7u7jir9v1y7ds3V1ZUgiKNHjyKVtUtPT+fz+XZ2dps3b3Z0dOTz+f7+/tevX0cIRUdHc7lcBwcHqsz33ntPJBIRBNHW1hYTExMbG1tXV0cQhKenJ0Lo0qVLEolk//79Oq8LRXp6OkmSQUFBI3clJSVNmzbt5MmTly9fHrmXJMkjR4689NJLPB7Pyspq5cqVt2/fVn1NkC4aF2nSvlZWVosWLUpLSzPEmwKpBQih3Nxc1Xl2795NEMRnn33W0dEhk8kyMzMRQhUVFSRJ7tixg8fjFRQUdHR07Nq1i8Vi3bhxgzoEIfT99993dXW1tLQsXLhQJBL19/f39vZKJJLDhw/L5fLm5uZVq1a1traqKEdNnj17JhaLo6Oj1ckcFhYWFhamfuEkSVJdnYyMDPqCjFo7kiSjoqJEIlFNTc3z58+rq6vnzZsnFosfPnxIkuS6devs7e3pMpOTkxFCVPVDQ0OlUim9q7i4WCwWJyYmahQkSZLUbT1uNg8PjxkzZgxLlEqlDx48IEnyhx9+YLFYU6ZM6e3tJUmypKQkODiYypOQkMDlck+dOtXZ2VlZWenr62tjY9Pc3Kz6mmjZuOSI9t23b5+zs7OlpSWHw5kyZUpwcPCPP/6onD8+Pp6+RVWjzv2v6nDGR6pzbplMJhQKX3/9dTqF+n9WUVEhl8uFQmFERASdk8fjvfvuu+RvLSGXy6ldlFzv3btH9cuLi4uVT6GiHDXZvXv3tGnTuru71cmsK+2NrB1JklFRURYWFvSBN27cQAjt3buX1ER7jFFHe729vQRBBAYGDkuntUeSZGxsLEJo69atpJL2ZDKZubk53UwkSf74448IIep/xFjXRPvGJUe078OHD2/evNnT09PX11dWVjZnzhyBQPDLL7/Q+b/44guE0JdffjluyVpqT799znv37slksiVLlozcdefOHZlMRn3eRQgJBAIHBweqEzIMahUghULh4eFhZ2e3fv36PXv21NfXa1rOqBQWFubl5X3zzTfKnw0MCV27kbvmzp0rFArVr4sBaGlpIUlSKBSqyJOUlDR9+vTMzMxr167RidXV1b29vXPnzqVT5s2bx+VyqU71MOhromXjotHa18XFZc6cOebm5lwu18/PLzs7Wy6XU2qnoGr35MkT9c/CDP1qj/qFka2t7chdz549Qwh99NFH9DBLQ0OD6rdhgUBw5cqVgICA/fv3e3h4REREyOVyBuXQ5OTkHDp0qLS0dMqUKQxqZwB4PJ7ymkjYef78OUKIx+OpyMPn87OzswmC2Lhxo1wupxKpD/fDVha1tLTs6elRUZQ2jYvUa9+ZM2eamZndvXuXThEIBOi3muoV/WqP+hTW19c3chclyNTUVOWncFlZmeoCvb29L1y40NTUFBcXl5ubm5KSwqwchFBGRsbp06evXLkyefJkJnXTPwqForOz09nZGXcg/wt1X447AL1gwYLt27fX1tbu27ePSrG0tEQIDVPauLVj3LhI7fYdGhoaGhpS/m9Crb9I1VSv6Fd7Pj4+LBbr6tWrI3e5uLjw+XyNJrg0NTXV1NQghGxtbQ8ePOjr61tTU8OgHJIk4+LiqqqqioqKRq7xbDyUlpaSJOnn54cQYrPZo/ZLDYydnR1BEOqM4O3bt8/Ly6uiooLa9PHxMTc3/+mnn+gM169f7+/vV73gBYPGReO17xtvvKG8SX25Uf7tOVU7e3t7jU7KAP1qz9bWNjQ0tKCgICsrq7u7u7Ky8vjx49QuPp+/YcOGM2fOHDt2rLu7e3BwsLGx8ddff1VRWlNT0+bNm2/fvt3f319RUdHQ0ODn58egnJqamk8//fTEiRMcDkd5blFKSoouK8+IoaGhjo6OgYGBysrKmJgYV1fXyMhIhJCnp+fTp0+LiooUCkVra2tDQwN9iLW1dVNTU319fU9Pj0KhKCkp0d8Yg1Ao9PDwUGexAqrnSQ+y8fn82NjYwsLC06dPd3d3V1VVbdmyxdHRMSoqSnUhYzVuRESEvb39qFPVVLfv48ePc3JyOjs7FQpFWVnZpk2bXF1dt2zZQh9O1W7mzJmaXBhGMP5KQ6r3naenp2fTpk2TJk0yNzcPCAhISEhACDk7O//88899fX1xcXGurq5sNptSaXV1dWZmJvWyO3Xq1Lq6uuPHj0skEoSQm5vbd9995+/vb2VlZWZmNnny5N27dw8MDJAkOWo5KkKqqqoa9VIkJyePW2VNv3NmZGRQ43JCoTAoKEhF7e7evRsVFcXhcJycnNhstkQiWblyZV1dHVVOe3v7a6+9xufz3d3d33//fWqY1NPTk/pq5+bmJhAIAgICmpubL168KBaLk5KS1A+SQs0xhujoaA6HI5PJqM3CwkKpVIoQsrGxob5tKrNz5056jGFoaCg5OXnq1KkcDsfKyiokJOTOnTskSaq+JmM1bkhICEIoISFhZISq2zc2NlYqlYpEIjab7ezs/M477zQ1NSkfvmLFCicnp6GhoXEvhTr3v6rDGR+p/blNEQZjDOpDTYPSU+Hjoqb2amtr2Wz2sGlZhmdwcHDhwoVZWVm6LbatrY3P56ekpKiTWcv7/wWdz2m0GHIePTM8PT0TExMTExP198uPcRkcHCwqKurp6VFhxMuMPXv2zJ49Ozo6WrfFjsrE1N7t27eJsdF5g71oxMfHr169OiIiAte06dLS0rNnz5aUlKgeadSUI0eO3Lp16+LFi6O6i+qciak9Ly8vFc/6nJwc3AGOwq5du7Kzs7u6utzd3Y1/rb79+/dHR0cfPHgQy9mXLFny1Vdf0RNcdcK5c+f6+vpKS0sN5lmv7RqBgK44cODAgQMHcEehAUuXLl26dCnuKHRGcHBwcHCwIc84MZ97AGD8gPYAAA+gPQDAA2gPAPAA2gMATDAelScn4vJbAKAR2sxr0XaMISYmhrH/mCmSmpqKENq2bRvuQHRPWVlZWloaswVRXkzCw8O1OVxb7S1YsOCF8gCjLLImapXT0tImatX0gZbag/c9AMADaA8A8ADaAwA8gPYAAA+gPQDAAx7tKRtHUXC5XDs7u8WLFycnJ3d0dGCJCtAGY7YEO3z4sJeXl0AgEIlEXl5eH3/8MeUmYHjfr/+DlmPr2owtSqVSahlmaoGgv//975GRkQRBODo6arrut8HQ65oReFFzzYhRSUhICAwMpNd+pizB0IhFxJWXiDckK1asSElJaWlp6enpycvL43A49FrpaWlpixYt6ujoYFCslve/UfQ5CYKwtLRcvHhxdnZ2Xl7ekydPKN8s3HEZGp24eYEl2Ei4XO57771na2trbm6+evXqlStXfvfdd9R6Zwb2/VLGKLSnTFhYWGRkZEtLy+eff447FkOjEzcvsAQbSWFhoXJ4Tk5OCCF6vRlD+n4pY3TaQwhRK1KWlJQgY/IJ0whyDL8r9d28wBJMf5ZgtbW1lpaWbm5u1KZBfb+UYdxb1b6/S7/vDYNSi4uLC2k0PmE0ar7vqfC7Ut9RyMCWYMze90zIEqy/v7+xsTEjI4PH4w1b41B93y9ltLz/jVF7JElSb4DG4xNGo472VPtdaaQ9Q1qC9oQvZQAAAkNJREFUMdCeaVmCUcu8T5o06d///d8pJdOo7/uljJb3vzH2OZ89e0aSpEQiMRKfME3RyO9KfcASTMt2fPToUUtLy9/+9rf//M//nDNnjvJbscF8v5QxRu1RhkxeXl7G4BPGAGZ+V+oAlmBIi3bkcDi2trZLly7Nycmprq5WXhXOYL5fyhij9i5duoQQWrZsGXafMGYw87saF7AE01U7enp6mpmZVVdX0ykG8/1Sxui019zcnJqa6uzsvHHjRow+Ydqg2u+KsZsXWIIxa8f29vY333xTOaW2tnZwcNDFxYVOMZjvlzKYtUeSZG9vL+X50trampub++qrr5qZmRUVFUkkEow+Ydqg2u9KfTcvBJZgIwphYAkmEom+/fbbK1eudHd3KxSKioqKP//5zyKRaPv27XQew/l+KcP4Kw2pxXee8+fPz5o1SygUcrlcFouFfpvaMn/+/MTExPb2djonLp+wsVBzjGEsvytSEzcvA1uCMRtjMH5LMJIkg4KC3N3dzc3NeTyeVCqNiIioqqpSzqC+75cyjO///3844yO1P7cpYsj5nAa2BGOmvQlgCaaR75cyWt7/Rve+BygDlmDqoKUlmCF9v5QB7QHaYtKWYAb2/VIGtGekgCWY+jC2BDO875cy4AFmpIAlmAEwvO+XMvDcAwA8gPYAAA+gPQDAA2gPAPCg7bcW/c1INk6oyUd5eXm4A9E9VFNOyKoZKYxH5UnwAANeeLSZ10KAhAAAC/C+BwB4AO0BAB5AewCAB9AeAODh/wHQt5Ni4O9lNgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Salvo il modello e lo converto(salvo sia in .h5 che in tflite)\n",
        "\n",
        "model.save('modello_asc' + '.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimization = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "open('modello_asc' + '.tflite','wb').write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu4BEWs1PeZ2",
        "outputId": "da9309aa-12df-4431-bd21-ce0c2e215773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5704"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVqcWIrRt8TN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85910de-0899-433b-93f4-544f332ed212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10, 11, 12, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install q keras==2.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmZ-4z3bZH8E",
        "outputId": "28843ab3-93f9-4d4a-ab6a-010fdb327120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting q\n",
            "  Downloading q-2.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting keras==2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: q, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires keras<2.12,>=2.11.0, but you have keras 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.10.0 q-2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definisco il modello da usare le la grid_search\n",
        "\n",
        "def define_model(neurons = 10,learning_rate = 0.001, momentum = 0.3):\n",
        "    my_model = Sequential()\n",
        "    my_model.add(Dense(neurons,activation = 'relu',kernel_initializer = 'uniform',input_dim = 6))\n",
        "    my_model.add(Dense(neurons,activation = 'relu',kernel_initializer = 'uniform'))\n",
        "    my_model.add(Dense(3,activation = 'softmax',kernel_initializer = 'uniform'))\n",
        "    optimizer = SGD(lr = learning_rate, momentum = momentum)\n",
        "    my_model.compile(loss = 'categorical_crossentropy',optimizer = optimizer,metrics = ['accuracy'])\n",
        "    return my_model     "
      ],
      "metadata": {
        "id": "UoUWvwnCwks4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning degli iperparametri\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 100\n",
        "my_model = KerasClassifier(neurons = 1,learning_rate = 0,momentum = 0,build_fn = define_model,epochs = epochs, batch_size = batch_size, verbose = 1)\n",
        "learning_rate = [0.001,0.01,0.1]\n",
        "momentum = [0.3,0.7,0.9]\n",
        "neurons = [10,11,12,13,14,15]\n",
        "param_grid = dict(learning_rate=learning_rate,momentum=momentum,neurons = neurons)\n",
        "grid = GridSearchCV(estimator=my_model, param_grid = param_grid, n_jobs=16, cv =3)\n",
        "grid.fit(X_train, Y_train) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKOF5PPbz4H_",
        "outputId": "e5fee022-7ac1-4aa0-b1d5-e1a129e22950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scikeras/wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1578 - accuracy: 0.3667\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0874 - accuracy: 0.3133\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0647 - accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0564 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0188 - accuracy: 0.3267\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0000 - accuracy: 0.3200\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9617 - accuracy: 0.3200\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9505 - accuracy: 0.3133\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9227 - accuracy: 0.3600\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9144 - accuracy: 0.4933\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8994 - accuracy: 0.4800\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8923 - accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8937 - accuracy: 0.5400\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8854 - accuracy: 0.5667\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8777 - accuracy: 0.5467\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8678 - accuracy: 0.5733\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8654 - accuracy: 0.5867\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8590 - accuracy: 0.6067\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8372 - accuracy: 0.5933\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8706 - accuracy: 0.5933\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8332 - accuracy: 0.6267\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8368 - accuracy: 0.6200\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8209 - accuracy: 0.7200\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8404 - accuracy: 0.6667\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8004 - accuracy: 0.6400\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8220 - accuracy: 0.6467\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7803 - accuracy: 0.6733\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7706 - accuracy: 0.7267\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.6733\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7140 - accuracy: 0.6933\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.6867\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.6800\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7751 - accuracy: 0.6067\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0865 - accuracy: 0.5800\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.6933\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.7133\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.7467\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7183 - accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8061 - accuracy: 0.6133\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6867\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.6933\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.7533\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.7067\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3725 - accuracy: 0.4933\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7967 - accuracy: 0.5800\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7660 - accuracy: 0.6000\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7222 - accuracy: 0.6467\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.6400\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.6533\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.7267\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7400\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.7133\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6933\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7667\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7400\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7533\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.7000\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7133\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7867\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7667\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.7200\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7067\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7667\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.7467\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7467\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.7000\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8439 - accuracy: 0.5400\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7600\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7333\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7400\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7800\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.7267\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7933\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.8067\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7400\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7333\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7867\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7533\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7333\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7867\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7533\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.8333\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.6933\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7800\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7533\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7800\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6867\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7533\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7333\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.8267\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7867\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7600\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7733\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7800\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8267\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8200\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8000\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7800\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=KerasClassifier(batch_size=16, build_fn=<function define_model at 0x7f265d7faf70>, epochs=100, learning_rate=0, momentum=0, neurons=1),\n",
              "             n_jobs=16,\n",
              "             param_grid={'learning_rate': [0.001, 0.01, 0.1],\n",
              "                         'momentum': [0.3, 0.7, 0.9],\n",
              "                         'neurons': [10, 11, 12, 13, 14, 15]})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}